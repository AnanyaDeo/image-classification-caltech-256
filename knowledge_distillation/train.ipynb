{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numexpr as ne\n",
    "import time\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('../pytorch_utils/')\n",
    "from utils import evaluate, get_data, top5_accuracy, per_class_accuracy, count_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.cuda\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, X_val, Y_train, Y_val = get_data()\n",
    "train_size = len(X_train)\n",
    "val_size = len(X_val)\n",
    "print(train_size, val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_logits = np.load('/home/ubuntu/data/train_logits.npy')[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temperature = 20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_models = len(train_logits)\n",
    "n_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soft_targets = torch.zeros(train_size, 256)\n",
    "for k in train_logits:\n",
    "    soft_targets += F.softmax(torch.FloatTensor(train_logits[k])/temperature)\n",
    "soft_targets /= n_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TripleDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_tensor, target_tensor, third_tensor):\n",
    "        assert data_tensor.size(0) == target_tensor.size(0)\n",
    "        self.data_tensor = data_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "        self.third_tensor = third_tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_tensor[index], self.target_tensor[index], self.third_tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_tensor.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_data = TensorDataset(\n",
    "    torch.FloatTensor(X_val), \n",
    "    torch.LongTensor(Y_val)\n",
    ")\n",
    "\n",
    "val_iterator = DataLoader(\n",
    "    val_data, batch_size=64, shuffle=True, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = TripleDataset(\n",
    "    torch.FloatTensor(X_train), \n",
    "    torch.LongTensor(Y_train),\n",
    "    soft_targets\n",
    ")\n",
    "\n",
    "train_iterator = DataLoader(\n",
    "    train_data, batch_size=batch_size, shuffle=True, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../squeezenet/')\n",
    "from model_squeezenet import make_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, criterion, optimizer = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class soft_targets_logloss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(soft_targets_logloss, self).__init__()\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        x = F.log_softmax(logits)\n",
    "        return -(targets*x).sum(1).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soft_criterion = soft_targets_logloss()\n",
    "logloss_weight = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, x_batch, y_batch, soft_y_batch):\n",
    "\n",
    "    x_batch = Variable(x_batch.cuda())\n",
    "    y_batch = Variable(y_batch.cuda(async=True))\n",
    "    soft_y_batch = Variable(soft_y_batch.cuda(async=True))\n",
    "    \n",
    "    logits = model(x_batch)\n",
    "\n",
    "    # compute logloss\n",
    "    logloss = criterion(logits, y_batch)\n",
    "    batch_loss = logloss.data[0]\n",
    "\n",
    "    # compute accuracy\n",
    "    pred = F.softmax(logits).max(1)[1]\n",
    "    batch_accuracy = pred.eq(y_batch).float().mean().data[0]\n",
    "\n",
    "    # compute loss\n",
    "    loss = logloss_weight*logloss + soft_criterion(logits/temperature, soft_y_batch)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return batch_loss, batch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 6\n",
    "validation_step = 200\n",
    "n_batches = int(np.ceil(train_size/batch_size))\n",
    "M = 3\n",
    "T = n_batches*n_epochs\n",
    "initial = 0.01\n",
    "n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr_scheduler(optimizer, step):\n",
    "    \n",
    "    global initial\n",
    "    decay = np.cos(np.pi*((step - 1) % (T // M))/(T // M)) + 1.0\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = initial*decay/2.0\n",
    "    \n",
    "    if (step - 1) % (T // M) == 0 and step != 1:\n",
    "        initial *= 0.9\n",
    "        print('lr is reset:', initial)\n",
    "        \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_losses = []\n",
    "all_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "running_loss = 0.0\n",
    "running_accuracy = 0.0 \n",
    "start = time.time()\n",
    "model.train()\n",
    "\n",
    "for epoch in range(0, n_epochs):\n",
    "    for step, (x_batch, y_batch, soft_y_batch) in enumerate(train_iterator, 1 + epoch*n_batches):\n",
    "        \n",
    "        optimizer = lr_scheduler(optimizer, step)\n",
    "        batch_loss, batch_accuracy = train(\n",
    "            model, criterion, optimizer, \n",
    "            x_batch, y_batch, soft_y_batch\n",
    "        )\n",
    "        running_loss += batch_loss\n",
    "        running_accuracy += batch_accuracy\n",
    "        \n",
    "        if step % validation_step == 0:\n",
    "            model.eval()\n",
    "            test_loss, test_accuracy = evaluate(\n",
    "                model, criterion, val_iterator\n",
    "            )\n",
    "            end = time.time()\n",
    "            \n",
    "            print('{0:.2f}  {1:.3f} {2:.3f}  {3:.3f} {4:.3f}  {5:.3f}'.format(\n",
    "                step/n_batches, running_loss/validation_step, test_loss, \n",
    "                running_accuracy/validation_step, test_accuracy, end - start\n",
    "            ))\n",
    "            all_losses += [(\n",
    "                step/n_batches,\n",
    "                running_loss/validation_step, test_loss, \n",
    "                running_accuracy/validation_step, test_accuracy\n",
    "            )] \n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0 \n",
    "            start = time.time()\n",
    "            model.train()\n",
    "            \n",
    "        if step % (T // M) == 0:\n",
    "            \n",
    "            print('saving')\n",
    "            model.cpu()\n",
    "            clone = copy.deepcopy(model)\n",
    "            all_models += [clone.state_dict()]\n",
    "            model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss/epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = [x[0] for x in all_losses]\n",
    "plt.plot(epochs, [x[1] for x in all_losses], label='train');\n",
    "plt.plot(epochs, [x[2] for x in all_losses], label='test');\n",
    "plt.legend();\n",
    "plt.xlabel('epoch');\n",
    "plt.ylabel('loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, [x[3] for x in all_losses], label='train');\n",
    "plt.plot(epochs, [x[4] for x in all_losses], label='test');\n",
    "plt.legend();\n",
    "plt.xlabel('epoch');\n",
    "plt.ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict val. set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_iterator_no_shuffle = DataLoader(\n",
    "    val_data, batch_size=32, shuffle=False, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# model.load_state_dict(all_models[-1])\n",
    "model.eval()\n",
    "\n",
    "for x_batch, _ in val_iterator_no_shuffle:\n",
    "\n",
    "    x_batch = Variable(x_batch.cuda(), volatile=True)\n",
    "    logits = model(x_batch)\n",
    "\n",
    "    # compute probabilities\n",
    "    probs = F.softmax(logits) \n",
    "    val_predictions += [probs.cpu().data.numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_predictions = np.concatenate(val_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(Y_val, val_predictions.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_loss(Y_val, val_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Try ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_predictions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, state in enumerate(all_models):\n",
    "    \n",
    "    model.load_state_dict(state)\n",
    "    ensemble_predictions[i] = []\n",
    "    model.eval()\n",
    "    \n",
    "    for x_batch, _ in val_iterator_no_shuffle:\n",
    "\n",
    "        x_batch = Variable(x_batch.cuda(), volatile=True)\n",
    "        logits = model(x_batch)\n",
    "\n",
    "        # compute probabilities\n",
    "        probs = F.softmax(logits) \n",
    "        ensemble_predictions[i] += [probs.cpu().data.numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ensemble_predictions = {\n",
    "    p: np.concatenate(ensemble_predictions[p], axis=0) \n",
    "    for p in ensemble_predictions\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = np.stack(ensemble_predictions.values()).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(Y_val, predictions.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_loss(Y_val, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top5_accuracy(Y_val, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "per_class_acc = per_class_accuracy(Y_val, predictions)\n",
    "per_class_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "erroneous = Y_val != predictions.argmax(1)\n",
    "n_errors = len(Y_val[erroneous])\n",
    "n_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_show = np.random.choice(np.arange(0, n_errors), size=30, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pictures = X_val[erroneous][to_show].copy()\n",
    "pictures_predictions = predictions.argmax(1)[erroneous][to_show]\n",
    "pictures_probs = predictions.max(1)[erroneous][to_show]\n",
    "pictures_true = Y_val[erroneous][to_show]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406], dtype='float32')\n",
    "std = np.array([0.229, 0.224, 0.225], dtype='float32')\n",
    "decode = np.load('../utils/decode.npy')[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pictures = np.transpose(pictures, axes=(0, 2, 3, 1))\n",
    "ne.evaluate('pictures*std', out=pictures);\n",
    "ne.evaluate('pictures + mean', out=pictures);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show pictures, predicted classes and probabilities\n",
    "_, axes = plt.subplots(nrows=6, ncols=5, figsize=(14, 16))\n",
    "axes = axes.flatten()\n",
    "for i, pic in enumerate(pictures):\n",
    "    axes[i].set_axis_off();\n",
    "    axes[i].imshow(pic);\n",
    "    title = decode[pictures_predictions[i] + 1] + ' ' +\\\n",
    "        str(pictures_probs[i]) + '\\ntrue: ' + decode[pictures_true[i] + 1]\n",
    "    axes[i].set_title(title);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, m in enumerate(all_models):\n",
    "    torch.save(m, 'model_state' + str(i) + '.pytorch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
