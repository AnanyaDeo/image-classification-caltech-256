{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numexpr as ne\n",
    "import time\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('../pytorch_utils/')\n",
    "from utils import train, evaluate, get_data, top5_accuracy, per_class_accuracy, count_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.cuda\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51200 5120\n",
      "CPU times: user 1min 31s, sys: 10.3 s, total: 1min 41s\n",
      "Wall time: 40.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_val, Y_train, Y_val = get_data()\n",
    "train_size = len(X_train)\n",
    "val_size = len(X_val)\n",
    "print(train_size, val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_data = TensorDataset(\n",
    "    torch.FloatTensor(X_val), \n",
    "    torch.LongTensor(Y_val)\n",
    ")\n",
    "\n",
    "val_iterator = DataLoader(\n",
    "    val_data, batch_size=64, shuffle=True, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(\n",
    "    torch.FloatTensor(X_train), \n",
    "    torch.LongTensor(Y_train)\n",
    ")\n",
    "\n",
    "train_iterator = DataLoader(\n",
    "    train_data, batch_size=batch_size, shuffle=True, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model_densenet import make_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, criterion, optimizer = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7216256"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 2\n",
    "validation_step = 200\n",
    "n_batches = int(np.ceil(train_size/batch_size))\n",
    "M = 1\n",
    "T = n_batches*n_epochs\n",
    "initial = 0.01\n",
    "n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr_scheduler(optimizer, step):\n",
    "    \n",
    "    global initial\n",
    "    decay = np.cos(np.pi*((step - 1) % (T // M))/(T // M)) + 1.0\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = initial*decay/2.0\n",
    "    \n",
    "    if (step - 1) % (T // M) == 0 and step != 1:\n",
    "        # initial *= 0.5\n",
    "        print('lr is reset:', initial)\n",
    "        \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_losses = []\n",
    "all_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12  3.286 1.685  0.427 0.676  63.527\n",
      "0.25  1.402 1.094  0.738 0.767  60.214\n",
      "0.38  1.072 0.956  0.794 0.802  60.651\n",
      "0.50  0.971 0.899  0.819 0.810  60.586\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "running_loss = 0.0\n",
    "running_accuracy = 0.0 \n",
    "start = time.time()\n",
    "model.train()\n",
    "\n",
    "for epoch in range(0, n_epochs):\n",
    "    for step, (x_batch, y_batch) in enumerate(train_iterator, 1 + epoch*n_batches):\n",
    "        \n",
    "        optimizer = lr_scheduler(optimizer, step)\n",
    "        batch_loss, batch_accuracy = train(\n",
    "            model, criterion, optimizer, \n",
    "            x_batch, y_batch\n",
    "        )\n",
    "        running_loss += batch_loss\n",
    "        running_accuracy += batch_accuracy\n",
    "        \n",
    "        if step % validation_step == 0:\n",
    "            model.eval()\n",
    "            test_loss, test_accuracy = evaluate(\n",
    "                model, criterion, val_iterator\n",
    "            )\n",
    "            end = time.time()\n",
    "            \n",
    "            print('{0:.2f}  {1:.3f} {2:.3f}  {3:.3f} {4:.3f}  {5:.3f}'.format(\n",
    "                step/n_batches, running_loss/validation_step, test_loss, \n",
    "                running_accuracy/validation_step, test_accuracy, end - start\n",
    "            ))\n",
    "            all_losses += [(\n",
    "                step/n_batches,\n",
    "                running_loss/validation_step, test_loss, \n",
    "                running_accuracy/validation_step, test_accuracy\n",
    "            )] \n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0 \n",
    "            start = time.time()\n",
    "            model.train()\n",
    "            \n",
    "        if step % (T // M) == 0:\n",
    "            \n",
    "            print('saving')\n",
    "            model.cpu()\n",
    "            clone = copy.deepcopy(model)\n",
    "            all_models += [clone.state_dict()]\n",
    "            model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss/epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = [x[0] for x in all_losses]\n",
    "plt.plot(epochs, [x[1] for x in all_losses], label='train');\n",
    "plt.plot(epochs, [x[2] for x in all_losses], label='test');\n",
    "plt.legend();\n",
    "plt.xlabel('epoch');\n",
    "plt.ylabel('loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, [x[3] for x in all_losses], label='train');\n",
    "plt.plot(epochs, [x[4] for x in all_losses], label='test');\n",
    "plt.legend();\n",
    "plt.xlabel('epoch');\n",
    "plt.ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict val. set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_iterator_no_shuffle = DataLoader(\n",
    "    val_data, batch_size=32, shuffle=False, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# model.load_state_dict(all_models[-1])\n",
    "model.eval()\n",
    "\n",
    "for x_batch, _ in val_iterator_no_shuffle:\n",
    "\n",
    "    x_batch = Variable(x_batch.cuda(), volatile=True)\n",
    "    logits = model(x_batch)\n",
    "\n",
    "    # compute probabilities\n",
    "    probs = F.softmax(logits) \n",
    "    val_predictions += [probs.cpu().data.numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_predictions = np.concatenate(val_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(Y_val, val_predictions.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_loss(Y_val, val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top5_accuracy(Y_val, val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "per_class_acc = per_class_accuracy(Y_val, val_predictions)\n",
    "per_class_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "erroneous = Y_val != val_predictions.argmax(1)\n",
    "n_errors = len(Y_val[erroneous])\n",
    "n_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_show = np.random.choice(np.arange(0, n_errors), size=30, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pictures = X_val[erroneous][to_show].copy()\n",
    "pictures_predictions = val_predictions.argmax(1)[erroneous][to_show]\n",
    "pictures_probs = val_predictions.max(1)[erroneous][to_show]\n",
    "pictures_true = Y_val[erroneous][to_show]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406], dtype='float32')\n",
    "std = np.array([0.229, 0.224, 0.225], dtype='float32')\n",
    "decode = np.load('../utils/decode.npy')[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pictures = np.transpose(pictures, axes=(0, 2, 3, 1))\n",
    "ne.evaluate('pictures*std', out=pictures);\n",
    "ne.evaluate('pictures + mean', out=pictures);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show pictures, predicted classes and probabilities\n",
    "_, axes = plt.subplots(nrows=6, ncols=5, figsize=(14, 16))\n",
    "axes = axes.flatten()\n",
    "for i, pic in enumerate(pictures):\n",
    "    axes[i].set_axis_off();\n",
    "    axes[i].imshow(pic);\n",
    "    title = decode[pictures_predictions[i] + 1] + ' ' +\\\n",
    "        str(pictures_probs[i]) + '\\ntrue: ' + decode[pictures_true[i] + 1]\n",
    "    axes[i].set_title(title);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, m in enumerate(all_models):\n",
    "    torch.save(m, 'model_state' + str(i) + '.pytorch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
