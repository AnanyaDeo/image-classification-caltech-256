{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D,\\\n",
    "    Activation, Dropout, GlobalAveragePooling2D, concatenate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = np.load('images.npy')\n",
    "targets = np.load('targets.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_classes = np.unique(targets)\n",
    "# class name -> integer\n",
    "encode = {n: i for i, n in enumerate(unique_classes)}\n",
    "# integer -> class name\n",
    "decode = {i: n for i, n in enumerate(unique_classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode class names by integers\n",
    "targets = np.array([encode[n] for n in targets], dtype='int32')\n",
    "targets_onehot = to_categorical(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this values are taken from here \n",
    "# http://pytorch.org/docs/master/torchvision/models.html\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.6 s, sys: 2.87 s, total: 1min 1s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "images = images.astype('float32')\n",
    "images /= 255.0\n",
    "\n",
    "# standardize\n",
    "images -= mean\n",
    "images /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18785 3315\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    images, targets_onehot, \n",
    "    test_size=0.15, stratify=targets\n",
    ")\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del images\n",
    "del targets_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=35, \n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True, \n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.01,\n",
    "    channel_shift_range=0.1,\n",
    "    fill_mode='reflect',\n",
    "    data_format='channels_last'\n",
    ")\n",
    "\n",
    "train_generator = data_generator.flow(\n",
    "        X_train, Y_train,\n",
    "        batch_size=len(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 28s, sys: 15.7 s, total: 2min 44s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_chunk, y_chunk = train_generator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pretrained weights of SqueezeNet v1.1\n",
    "weights = np.load('weights.npy')[()]\n",
    "# we don't need weights of the last layer\n",
    "del weights['conv10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a building block of the SqueezeNet architecture\n",
    "def fire_module(number, x, squeeze, expand, trainable=False):\n",
    "    \n",
    "    module_name = 'fire' + number\n",
    "    \n",
    "    x = Convolution2D(\n",
    "        squeeze, (1, 1), \n",
    "        name=module_name + '/' + 'squeeze',\n",
    "        trainable=trainable\n",
    "    )(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    a = Convolution2D(\n",
    "        expand, (1, 1),\n",
    "        name=module_name + '/' + 'expand1x1',\n",
    "        trainable=trainable\n",
    "    )(x)\n",
    "    a = Activation('relu')(a)\n",
    "\n",
    "    b = Convolution2D(\n",
    "        expand, (3, 3), padding='same',\n",
    "        name=module_name + '/' + 'expand3x3',\n",
    "        trainable=trainable\n",
    "    )(x)\n",
    "    b = Activation('relu')(b)\n",
    "\n",
    "    return concatenate([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SqueezeNet():\n",
    "\n",
    "    image = Input(shape=(224, 224, 3))\n",
    "\n",
    "    x = Convolution2D(\n",
    "        64, (3, 3), strides=(2, 2), name='conv1', \n",
    "        trainable=False\n",
    "    )(image) # 111, 111, 64\n",
    "    \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x) # 55, 55, 64\n",
    "\n",
    "    x = fire_module('2', x, squeeze=16, expand=64) # 55, 55, 128\n",
    "    x = fire_module('3', x, squeeze=16, expand=64) # 55, 55, 128\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x) # 27, 27, 128\n",
    "\n",
    "    x = fire_module('4', x, squeeze=32, expand=128) # 27, 27, 256\n",
    "    x = fire_module('5', x, squeeze=32, expand=128) # 27, 27, 256\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x) # 13, 13, 256\n",
    "\n",
    "    x = fire_module('6', x, squeeze=48, expand=192) # 13, 13, 384\n",
    "    x = fire_module('7', x, squeeze=48, expand=192) # 13, 13, 384\n",
    "    x = fire_module('8', x, squeeze=64, expand=256) # 13, 13, 512\n",
    "    x = fire_module('9', x, squeeze=64, expand=256, trainable=True) # 13, 13, 512\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Convolution2D(\n",
    "        256, (1, 1), name='conv10',\n",
    "        kernel_initializer=keras.initializers.RandomNormal(stddev=0.01),\n",
    "        kernel_regularizer=keras.regularizers.l2(1e-2)\n",
    "    )(x) # 13, 13, 256\n",
    "    \n",
    "    x = Activation('relu')(x)\n",
    "    logits = GlobalAveragePooling2D()(x) # 256\n",
    "    classes = Activation('softmax')(logits)\n",
    "    \n",
    "    return Model(image, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "853824"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SqueezeNet()\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load pretrained weights into the model\n",
    "for k in [w for w in weights]:\n",
    "    model.get_layer(k).set_weights(weights[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add regularization to the last fire module\n",
    "model.get_layer('fire9/squeeze').kernel_regularizer = keras.regularizers.l2(1e-2)\n",
    "model.get_layer('fire9/expand1x1').kernel_regularizer = keras.regularizers.l2(1e-2)\n",
    "model.get_layer('fire9/expand3x3').kernel_regularizer = keras.regularizers.l2(1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18785 samples, validate on 3315 samples\n",
      "Epoch 1/6\n",
      "37s - loss: 3.5222 - acc: 0.3364 - val_loss: 2.3952 - val_acc: 0.5134\n",
      "Epoch 2/6\n",
      "36s - loss: 2.2949 - acc: 0.5410 - val_loss: 2.1577 - val_acc: 0.5689\n",
      "Epoch 3/6\n",
      "36s - loss: 2.0155 - acc: 0.6046 - val_loss: 2.0913 - val_acc: 0.5991\n",
      "Epoch 4/6\n",
      "36s - loss: 1.8555 - acc: 0.6401 - val_loss: 2.0275 - val_acc: 0.6069\n",
      "Epoch 5/6\n",
      "36s - loss: 1.7545 - acc: 0.6656 - val_loss: 2.0770 - val_acc: 0.6087\n",
      "Epoch 6/6\n",
      "36s - loss: 1.6586 - acc: 0.6898 - val_loss: 2.1262 - val_acc: 0.6012\n",
      "CPU times: user 1min 31s, sys: 21.9 s, total: 1min 53s\n",
      "Wall time: 3min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f71797a02b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(\n",
    "    x_chunk, y_chunk,\n",
    "    batch_size=64,\n",
    "    epochs=6, verbose=2,\n",
    "    validation_data=(X_test, Y_test)\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
