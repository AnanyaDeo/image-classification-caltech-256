{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import ceil\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../training_utils/')\n",
    "from data_utils import get_folders, get_class_weights\n",
    "from train_utils import train, predict\n",
    "from diagnostic_tools import top_k_accuracy, per_class_accuracy,\\\n",
    "    count_params, entropy, model_calibration, show_errors, most_confused_classes,\\\n",
    "    most_inaccurate_k_classes\n",
    "    \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16980"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder, val_folder = get_folders()\n",
    "\n",
    "train_iterator = DataLoader(\n",
    "    train_folder, batch_size=batch_size, num_workers=4,\n",
    "    shuffle=True, pin_memory=True\n",
    ")\n",
    "\n",
    "val_iterator = DataLoader(\n",
    "    val_folder, batch_size=64, num_workers=4,\n",
    "    shuffle=False, pin_memory=True\n",
    ")\n",
    "\n",
    "# number of training samples\n",
    "train_size = len(train_folder.imgs)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from get_resnet18_with_sd import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# w[j]: 1/number_of_samples_in_class_j\n",
    "# decode: folder name to class name (in human readable format)\n",
    "w, decode = get_class_weights(val_folder.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, criterion, optimizer = get_model(class_weights=torch.FloatTensor(w/w.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21416000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of params in the model\n",
    "count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_epochs = 20\n",
    "# n_batches = ceil(train_size/batch_size)\n",
    "# # number of cycles\n",
    "# M = 1 \n",
    "# # total number of optimization steps\n",
    "# T = n_batches*n_epochs \n",
    "# # initial learning rates\n",
    "# initial1 = 1e-2\n",
    "# initial2 = 1e-3\n",
    "# n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # cyclical cosine annealing\n",
    "# # it changes the learning rate on every optimization step\n",
    "# # 1e-6 is the minimal learning rate\n",
    "# def lr_scheduler(optimizer, step):\n",
    "    \n",
    "#     global initial1\n",
    "#     global initial2\n",
    "#     decay = np.cos(np.pi*((step - 1) % (T // M))/(T // M)) + 1.0\n",
    "    \n",
    "#     # params of the last fc layer\n",
    "#     for param_group in optimizer.param_groups[:2]:\n",
    "#         param_group['lr'] = ((initial1 - 1e-6)*decay/2.0) + 1e-6\n",
    "    \n",
    "#     # params of the last two resnet blocks\n",
    "#     for param_group in optimizer.param_groups[2:]:\n",
    "#         param_group['lr'] = ((initial2 - 1e-6)*decay/2.0) + 1e-6\n",
    "    \n",
    "#     if (step - 1) % (T // M) == 0 and step != 1:\n",
    "#         print('lr is reset')\n",
    "        \n",
    "#     return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "n_epochs = 50\n",
    "n_batches = ceil(train_size/batch_size)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.1, patience=6, \n",
    "    verbose=True, threshold=0.01, threshold_mode='abs'\n",
    ")\n",
    "\n",
    "n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00  4.941 2.761  0.139 0.469  0.300 0.727  100.975\n",
      "2.00  3.492 1.808  0.339 0.595  0.599 0.838  99.572\n",
      "3.00  2.932 1.769  0.424 0.658  0.685 0.864  100.329\n",
      "4.00  2.593 1.631  0.471 0.664  0.730 0.874  99.729\n",
      "5.00  2.348 1.550  0.517 0.679  0.764 0.882  100.449\n",
      "6.00  2.205 1.509  0.541 0.707  0.781 0.899  99.999\n",
      "7.00  2.065 1.502  0.564 0.713  0.799 0.891  99.814\n",
      "8.00  1.909 1.342  0.579 0.701  0.817 0.903  100.091\n",
      "9.00  1.789 1.301  0.606 0.733  0.831 0.909  99.909\n",
      "10.00  1.773 1.214  0.613 0.741  0.837 0.909  100.111\n",
      "11.00  1.657 1.223  0.635 0.744  0.848 0.909  99.998\n",
      "12.00  1.622 1.255  0.639 0.726  0.853 0.899  100.094\n",
      "13.00  1.541 1.132  0.655 0.749  0.864 0.917  100.279\n",
      "14.00  1.454 1.220  0.669 0.742  0.874 0.908  101.205\n",
      "15.00  1.434 1.085  0.675 0.747  0.875 0.915  100.064\n",
      "16.00  1.461 1.116  0.677 0.754  0.876 0.918  99.613\n",
      "17.00  1.356 1.088  0.687 0.762  0.884 0.920  99.560\n",
      "18.00  1.325 1.083  0.694 0.755  0.886 0.920  100.385\n",
      "19.00  1.230 1.034  0.708 0.756  0.899 0.920  99.964\n",
      "20.00  1.240 1.142  0.709 0.760  0.896 0.917  100.046\n",
      "21.00  1.264 1.068  0.707 0.754  0.895 0.920  99.654\n",
      "22.00  1.196 1.091  0.717 0.757  0.899 0.914  99.926\n",
      "23.00  1.181 1.043  0.719 0.771  0.902 0.920  100.585\n",
      "24.00  1.137 1.031  0.729 0.759  0.905 0.918  99.569\n",
      "25.00  1.090 1.114  0.740 0.758  0.908 0.918  100.167\n",
      "26.00  1.044 1.146  0.740 0.759  0.914 0.911  100.803\n",
      "27.00  1.063 1.018  0.744 0.765  0.917 0.917  101.959\n",
      "28.00  1.049 1.058  0.743 0.761  0.913 0.918  100.072\n",
      "29.00  0.986 1.028  0.757 0.761  0.922 0.917  99.888\n",
      "30.00  0.992 1.006  0.757 0.767  0.921 0.920  99.892\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch    29: reducing learning rate of group 1 to 1.0000e-03.\n",
      "Epoch    29: reducing learning rate of group 2 to 1.0000e-04.\n",
      "Epoch    29: reducing learning rate of group 3 to 1.0000e-04.\n",
      "Epoch    29: reducing learning rate of group 4 to 1.0000e-04.\n",
      "31.00  0.923 0.917  0.774 0.787  0.927 0.930  99.795\n",
      "32.00  0.842 0.976  0.796 0.785  0.935 0.930  99.912\n",
      "33.00  0.790 0.925  0.803 0.786  0.942 0.928  101.888\n",
      "34.00  0.809 0.923  0.801 0.791  0.936 0.929  99.966\n",
      "35.00  0.789 0.919  0.807 0.792  0.941 0.932  100.244\n",
      "36.00  0.785 0.897  0.806 0.788  0.940 0.929  100.073\n",
      "37.00  0.729 0.944  0.816 0.789  0.946 0.927  100.039\n",
      "38.00  0.768 0.909  0.809 0.791  0.943 0.931  101.316\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch    37: reducing learning rate of group 1 to 1.0000e-04.\n",
      "Epoch    37: reducing learning rate of group 2 to 1.0000e-05.\n",
      "Epoch    37: reducing learning rate of group 3 to 1.0000e-05.\n",
      "Epoch    37: reducing learning rate of group 4 to 1.0000e-05.\n",
      "39.00  0.789 0.896  0.809 0.790  0.944 0.928  101.696\n",
      "40.00  0.744 0.872  0.813 0.796  0.944 0.932  100.254\n",
      "41.00  0.768 0.873  0.813 0.793  0.943 0.932  100.092\n",
      "42.00  0.713 0.901  0.818 0.794  0.945 0.930  100.455\n",
      "43.00  0.774 0.930  0.812 0.786  0.942 0.928  100.807\n",
      "44.00  0.772 0.872  0.807 0.796  0.945 0.932  100.094\n",
      "45.00  0.779 0.875  0.806 0.793  0.944 0.928  99.676\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch    44: reducing learning rate of group 1 to 1.0000e-05.\n",
      "Epoch    44: reducing learning rate of group 2 to 1.0000e-06.\n",
      "Epoch    44: reducing learning rate of group 3 to 1.0000e-06.\n",
      "Epoch    44: reducing learning rate of group 4 to 1.0000e-06.\n",
      "46.00  0.759 0.881  0.813 0.795  0.942 0.931  100.128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-369:\n",
      "Process Process-372:\n",
      "Process Process-370:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process Process-371:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/datasets/folder.py\", line 116, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/datasets/folder.py\", line 63, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/datasets/folder.py\", line 46, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/datasets/folder.py\", line 118, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/PIL/Image.py\", line 860, in convert\n",
      "    self.load()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms.py\", line 34, in __call__\n",
      "    img = t(img)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/datasets/folder.py\", line 118, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/PIL/ImageFile.py\", line 188, in load\n",
      "    self.load_prepare()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms.py\", line 270, in __call__\n",
      "    return self.lambd(img)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/datasets/folder.py\", line 118, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms.py\", line 34, in __call__\n",
      "    img = t(img)\n",
      "  File \"../training_utils/data_utils.py\", line 32, in enhance\n",
      "    image = enhancers[i](image, f)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms.py\", line 34, in __call__\n",
      "    img = t(img)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms.py\", line 197, in __call__\n",
      "    return img.resize((ow, oh), self.interpolation)\n",
      "  File \"../training_utils/data_utils.py\", line 14, in <lambda>\n",
      "    1: lambda image, f: ImageEnhance.Contrast(image).enhance(f),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms.py\", line 270, in __call__\n",
      "    return self.lambd(img)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/PIL/Image.py\", line 1712, in resize\n",
      "    return self._new(self.im.resize(size, resample))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/PIL/ImageEnhance.py\", line 37, in enhance\n",
      "    return Image.blend(self.degenerate, self.image, factor)\n",
      "  File \"../training_utils/data_utils.py\", line 32, in enhance\n",
      "    image = enhancers[i](image, f)\n",
      "  File \"../training_utils/data_utils.py\", line 16, in <lambda>\n",
      "    3: lambda image, f: ImageEnhance.Sharpness(image).enhance(f)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/PIL/ImageEnhance.py\", line 97, in __init__\n",
      "    self.degenerate = image.filter(ImageFilter.SMOOTH)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/PIL/Image.py\", line 2560, in blend\n",
      "    return im1._new(core.blend(im1.im, im2.im, alpha))\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/PIL/Image.py\", line 1120, in filter\n",
      "    ims.append(self._new(filter.filter(self.im.getband(c))))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/PIL/ImageFilter.py\", line 54, in filter\n",
      "    return image.filter(*self.filterargs)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/work/image-classification-caltech-256/training_utils/train_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_iterator, n_epochs, n_batches, val_iterator, validation_step, n_validation_batches, saving_step, lr_scheduler)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlr_scheduler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_reduce_on_plateau\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_losses, _ = train(\n",
    "    model, criterion, optimizer, \n",
    "    train_iterator, n_epochs, n_batches, \n",
    "    val_iterator, validation_step=531, n_validation_batches=80, \n",
    "    saving_step=None, lr_scheduler=scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1e-4_1e-4 0.25 -> 38.00  1.044 0.923  0.757 0.793  0.916 0.930  99.657\n",
    "# 1e-5_1e-5 0.15 -> 46.00  0.759 0.881  0.813 0.795  0.942 0.931  100.128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use all blocks, drop 3\n",
    "# 1e-3_1e-3 1e-7_1e-7 + adam + drop_0.1 -> 24.00  2.621 2.872  0.429 0.386  0.675 0.640  93.682\n",
    "# 1e-3_1e-3 1e-7_1e-7 + RMSprop + drop_0.1 -> 4.00  5.084 5.034  0.048 0.040  0.152 0.135  93.993\n",
    "# 1e-2_1e-2 1e-7_1e-7 + RMSprop + drop_0.1 -> 2.00  5.518 5.468  0.008 0.009  0.039 0.040  93.607"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1e-2_1e-3 no drop 1e-3_1e-3 + cosine -> 20.00  2.303 2.124  0.540 0.641  0.754 0.849  93.557\n",
    "# 1e-2_1e-2 no drop 1e-3_1e-3 + on_plateau -> 29.00  1.738 1.990  0.615 0.565  0.816 0.792  93.393\n",
    "# 1e-1_1e-1 no drop 1e-5_1e-3 + on_plateau -> 5.00  5.763 5.700  0.003 0.004  0.016 0.020  93.239\n",
    "# 1e-3_1e-2 no drop 1e-5_1e-5 + on_plateau -> 28.00  2.043 2.832  0.589 0.552  0.790 0.785  93.372\n",
    "# use less blocks\n",
    "# 1e-3_1e-2 no drop 1e-5_1e-5 + on_plateau -> 26.00  1.775 1.972  0.633 0.665  0.826 0.863  92.524\n",
    "\n",
    "# 1e-3_1e-2 no drop 1e-7_1e-7 + no nesterov mom 0.95 -> 34.00  1.441 1.743  0.655 0.607  0.859 0.829  92.509\n",
    "# 1e-3_1e-2 no drop 1e-5_1e-5 + no nesterov mom 0.95 + more blocks -> 9.00  5.264 5.359  0.023 0.020  0.086 0.086  92.917\n",
    "# 2e-3_2e-2 no drop 1e-7_1e-7 + no nesterov mom 0.99 -> 9.00  5.528 5.539  0.004 0.006  0.019 0.026  93.480\n",
    "# 1e-3_1e-2 no drop 1e-7_1e-7 + no nesterov mom 0.9 + all blocks but not all drop -> 30.00  1.555 1.487  0.672 0.699  0.855 0.885  93.359\n",
    "# 1e-3_1e-2 no drop 1e-7_1e-7 + no nesterov mom 0.6 + drop_0.25 -> 28.00  3.010 3.794  0.469 0.602  0.694 0.819  93.513\n",
    "# 1e-4_1e-2 no drop 1e-7_1e-7 + no nesterov mom 0.97 + drop_0.25 -> 6.00  5.986 5.649  0.005 0.005  0.024 0.025  93.167\n",
    "# 1e-4_1e-2 no drop 1e-7_1e-7 + no nesterov mom 0.0 + drop_0.25 -> 6.00  4.453 5.431  0.227 0.043  0.421 0.098  93.215"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss/epoch plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = [x[0] for x in all_losses]\n",
    "plt.plot(epochs, [x[1] for x in all_losses], label='train');\n",
    "plt.plot(epochs, [x[2] for x in all_losses], label='val');\n",
    "plt.legend();\n",
    "plt.xlabel('epoch');\n",
    "plt.ylabel('loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, [x[3] for x in all_losses], label='train');\n",
    "plt.plot(epochs, [x[4] for x in all_losses], label='val');\n",
    "plt.legend();\n",
    "plt.xlabel('epoch');\n",
    "plt.ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, [x[5] for x in all_losses], label='train');\n",
    "plt.plot(epochs, [x[6] for x in all_losses], label='val');\n",
    "plt.legend();\n",
    "plt.xlabel('epoch');\n",
    "plt.ylabel('top5_accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get human readable class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# index to class name\n",
    "decode = {val_folder.class_to_idx[k]: decode[int(k)] for k in val_folder.class_to_idx}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get all predictions and all misclassified images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_iterator_no_shuffle = DataLoader(\n",
    "    val_folder, batch_size=64, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions, val_true_targets,\\\n",
    "    erroneous_samples, erroneous_targets,\\\n",
    "    erroneous_predictions = predict(model, val_iterator_no_shuffle, return_erroneous=True)\n",
    "# erroneous_samples: images that were misclassified\n",
    "# erroneous_targets: their true labels\n",
    "# erroneous_predictions: predictions for them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of misclassified images (there are overall 5120 images in the val dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_errors = len(erroneous_targets)\n",
    "n_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logloss and accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(val_true_targets, val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(val_true_targets, val_predictions.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_k_accuracy(val_true_targets, val_predictions, k=(2, 3, 4, 5, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### entropy of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hits = val_predictions.argmax(1) == val_true_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    entropy(val_predictions[hits]), bins=30, \n",
    "    normed=True, alpha=0.7, label='correct prediction'\n",
    ");\n",
    "plt.hist(\n",
    "    entropy(val_predictions[~hits]), bins=30, \n",
    "    normed=True, alpha=0.5, label='misclassification'\n",
    ");\n",
    "plt.legend();\n",
    "plt.xlabel('entropy of predictions');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confidence of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    val_predictions[hits].max(1), bins=30, \n",
    "    normed=True, alpha=0.7, label='correct prediction'\n",
    ");\n",
    "plt.hist(\n",
    "    val_predictions[~hits].max(1), bins=30, \n",
    "    normed=True, alpha=0.5, label='misclassification'\n",
    ");\n",
    "plt.legend();\n",
    "plt.xlabel('confidence of predictions');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### difference between biggest and second biggest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_correct = np.sort(val_predictions[hits], 1)\n",
    "sorted_incorrect = np.sort(val_predictions[~hits], 1)\n",
    "\n",
    "plt.hist(\n",
    "    sorted_correct[:, -1] - sorted_correct[:, -2], bins=30, \n",
    "    normed=True, alpha=0.7, label='correct prediction'\n",
    ");\n",
    "plt.hist(\n",
    "    sorted_incorrect[:, -1] - sorted_incorrect[:, -2], bins=30, \n",
    "    normed=True, alpha=0.5, label='misclassification'\n",
    ");\n",
    "plt.legend();\n",
    "plt.xlabel('difference');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### probabilistic calibration of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_calibration(val_true_targets, val_predictions, n_bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### per class accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_class_acc = per_class_accuracy(val_true_targets, val_predictions)\n",
    "plt.hist(per_class_acc);\n",
    "plt.xlabel('accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_inaccurate_k_classes(per_class_acc, 15, decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class accuracy vs. number of samples in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter((1.0/w), per_class_acc);\n",
    "plt.ylabel('class accuracy');\n",
    "plt.xlabel('number of available samples');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most confused pairs of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confused_pairs = most_confused_classes(\n",
    "    val_true_targets, val_predictions, decode, min_n_confusions=4\n",
    ")\n",
    "confused_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### show some low entropy errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erroneous_entropy = entropy(erroneous_predictions)\n",
    "mean_entropy = erroneous_entropy.mean()\n",
    "low_entropy = mean_entropy < erroneous_entropy\n",
    "mean_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_errors(\n",
    "    erroneous_samples[low_entropy], \n",
    "    erroneous_predictions[low_entropy], \n",
    "    erroneous_targets[low_entropy], \n",
    "    decode\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### show some high entropy errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_errors(\n",
    "    erroneous_samples[~low_entropy], \n",
    "    erroneous_predictions[~low_entropy], \n",
    "    erroneous_targets[~low_entropy], \n",
    "    decode\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.cpu();\n",
    "torch.save(model.state_dict(), 'resnet18_with_sd.pytorch_state')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
